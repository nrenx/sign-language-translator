
# ASL Sign Language Model Training Report
Generated: 2025-11-21 03:46:03

## Environment Information
- TensorFlow Version: 2.19.0
- MediaPipe Version: 0.10.13
- Python Version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]
- GPU Available: 1 GPU(s)
- GPU Devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]

## Dataset Information
- Total Classes: 28
- Classes: A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, Space, T, U, V, W, X, Y, Z
- Total Images Processed: 165,782
- Successful Extractions: 151,479
- Skipped Images: 14,303 (8.6%)
- Feature Dimensions: 63

## Data Split
- Training Samples: 363,549 (240.0%)
- Validation Samples: 30,296 (20.0%)
- Augmentation Applied: True

## Model Architecture
- Model Type: Sequential MLP Classifier
- Input Shape: (63,)
- Total Parameters: 60,892
- Trainable Parameters: 60,124
- Layer Configuration:
  * Dense(256) + BatchNorm + Dropout(0.3)
  * Dense(128) + BatchNorm + Dropout(0.2)
  * Dense(64) + Dropout(0.1)
  * Dense(28, softmax)

## Training Configuration
- Optimizer: Adam
- Initial Learning Rate: 0.001
- Batch Size: 64
- Max Epochs: 100
- Epochs Trained: 11
- Early Stopping Patience: 10
- Learning Rate Reduction: ReduceLROnPlateau (factor=0.5, patience=5)

## Performance Metrics
### Training Results
- Final Train Loss: 0.0609
- Final Train Accuracy: 99.16%
- Final Val Loss: 0.0725
- Final Val Accuracy: 98.81%

### Best Results
- Best Validation Accuracy: 99.92%
- Best Validation Loss: 0.0374

### Model Generalization
- Train-Val Accuracy Gap: 0.35%
- Overfitting Status: Good generalization

## Output Files
- Best Model: /content/drive/MyDrive/asl_model_output/best_model.keras
- Labels File: /content/drive/MyDrive/asl_model_output/labels.json
- TFJS Model: /content/drive/MyDrive/asl_model_output/tfjs_model
- Training Plots: /content/drive/MyDrive/asl_model_output/training_history.png
- TensorBoard Logs: /content/drive/MyDrive/asl_model_output/logs

## Deployment Instructions
1. Download the entire output directory: /content/drive/MyDrive/asl_model_output
2. For web deployment:
   - Use model.json from tfjs_model/
   - Load labels from tfjs_model/labels.json
   - Input: 63 MediaPipe hand landmarks (wrist-centered)
   - Output: Probability distribution over 28 classes
3. Recommended: Implement smoothing (5-frame majority voting) for real-time predictions

## Notes
- Model uses wrist-centered MediaPipe landmarks (21 landmarks × 3 coordinates = 63 features)
- Labels format: Array of strings (not dictionary)
- Model expects normalized landmark coordinates (0-1 range)
- Recommended inference: Extract landmarks → Center at wrist → Predict

---
Report generated by ASL Model Training Pipeline
